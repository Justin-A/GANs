{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.datasets import ImageFolder, MNIST\n",
    "from torchvision import transforms\n",
    "from torch import autograd\n",
    "from torch.autograd import Variable\n",
    "from torchvision.utils import make_grid\n",
    "from tensorboardX import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(), transforms.Normalize([0.5], [0.5])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "data_loader = torch.utils.data.DataLoader(MNIST('data', train=True, download=True, transform=transform),\n",
    "                                          batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.label_emb = nn.Embedding(10, 10)\n",
    "        \n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(110, 256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(256, 512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(512, 1024),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(1024, 784),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "    \n",
    "    def forward(self, z, labels):\n",
    "        z = z.view(z.size(0), 100)\n",
    "        c = self.label_emb(labels)\n",
    "        x = torch.cat([z, c], 1)\n",
    "        out = self.model(x)\n",
    "        return out.view(x.size(0), 28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.label_emb = nn.Embedding(10, 10)\n",
    "        \n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(794, 1024),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x, labels):\n",
    "        x = x.view(x.size(0), 784)\n",
    "        c = self.label_emb(labels)\n",
    "        x = torch.cat([x, c], 1)\n",
    "        out = self.model(x)\n",
    "        return out.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = Generator().cuda()\n",
    "discriminator = Discriminator().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()\n",
    "d_optimizer = torch.optim.Adam(discriminator.parameters(), lr=1e-4)\n",
    "g_optimizer = torch.optim.Adam(generator.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_train_step(batch_size, discriminator, generator, g_optimizer, criterion):\n",
    "    g_optimizer.zero_grad()\n",
    "    z = Variable(torch.randn(batch_size, 100)).cuda()\n",
    "    fake_labels = Variable(torch.LongTensor(np.random.randint(0, 10, batch_size))).cuda()\n",
    "    fake_images = generator(z, fake_labels)\n",
    "    validity = discriminator(fake_images, fake_labels)\n",
    "    g_loss = criterion(validity, Variable(torch.ones(batch_size)).cuda())\n",
    "    g_loss.backward()\n",
    "    g_optimizer.step()\n",
    "    return g_loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_train_step(batch_size, discriminator, generator, d_optimizer, criterion, real_images, labels):\n",
    "    d_optimizer.zero_grad()\n",
    "\n",
    "    # train with real images\n",
    "    real_validity = discriminator(real_images, labels)\n",
    "    real_loss = criterion(real_validity, Variable(torch.ones(batch_size)).cuda())\n",
    "    \n",
    "    # train with fake images\n",
    "    z = Variable(torch.randn(batch_size, 100)).cuda()\n",
    "    fake_labels = Variable(torch.LongTensor(np.random.randint(0, 10, batch_size))).cuda()\n",
    "    fake_images = generator(z, fake_labels)\n",
    "    fake_validity = discriminator(fake_images, fake_labels)\n",
    "    fake_loss = criterion(fake_validity, Variable(torch.zeros(batch_size)).cuda())\n",
    "    \n",
    "    d_loss = real_loss + fake_loss\n",
    "    d_loss.backward()\n",
    "    d_optimizer.step()\n",
    "    return d_loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 0... Done!\n",
      "Starting epoch 1... Done!\n",
      "Starting epoch 2... Done!\n",
      "Starting epoch 3... Done!\n",
      "Starting epoch 4... Done!\n",
      "Starting epoch 5... Done!\n",
      "Starting epoch 6... Done!\n",
      "Starting epoch 7... Done!\n",
      "Starting epoch 8... Done!\n",
      "Starting epoch 9... Done!\n",
      "Starting epoch 10... Done!\n",
      "Starting epoch 11... Done!\n",
      "Starting epoch 12... Done!\n",
      "Starting epoch 13... Done!\n",
      "Starting epoch 14... Done!\n",
      "Starting epoch 15... Done!\n",
      "Starting epoch 16... Done!\n",
      "Starting epoch 17... Done!\n",
      "Starting epoch 18... Done!\n",
      "Starting epoch 19... Done!\n",
      "Starting epoch 20... Done!\n",
      "Starting epoch 21... Done!\n",
      "Starting epoch 22... Done!\n",
      "Starting epoch 23... Done!\n",
      "Starting epoch 24... Done!\n",
      "Starting epoch 25... Done!\n",
      "Starting epoch 26... Done!\n",
      "Starting epoch 27... Done!\n",
      "Starting epoch 28... Done!\n",
      "Starting epoch 29... Done!\n",
      "Starting epoch 30... Done!\n",
      "Starting epoch 31... Done!\n",
      "Starting epoch 32... Done!\n",
      "Starting epoch 33... Done!\n",
      "Starting epoch 34... Done!\n",
      "Starting epoch 35... Done!\n",
      "Starting epoch 36... Done!\n",
      "Starting epoch 37... Done!\n",
      "Starting epoch 38... Done!\n",
      "Starting epoch 39... Done!\n",
      "Starting epoch 40... Done!\n",
      "Starting epoch 41... Done!\n",
      "Starting epoch 42... Done!\n",
      "Starting epoch 43... Done!\n",
      "Starting epoch 44... Done!\n",
      "Starting epoch 45... Done!\n",
      "Starting epoch 46... Done!\n",
      "Starting epoch 47... Done!\n",
      "Starting epoch 48... Done!\n",
      "Starting epoch 49... Done!\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 50\n",
    "n_critic = 5\n",
    "display_step = 50\n",
    "for epoch in range(num_epochs):\n",
    "    print('Starting epoch {}...'.format(epoch), end=' ')\n",
    "    for i, (images, labels) in enumerate(data_loader):\n",
    "        \n",
    "        step = epoch * len(data_loader) + i + 1\n",
    "        real_images = Variable(images).cuda()\n",
    "        labels = Variable(labels).cuda()\n",
    "        generator.train()\n",
    "        \n",
    "        d_loss = discriminator_train_step(len(real_images), discriminator,\n",
    "                                          generator, d_optimizer, criterion,\n",
    "                                          real_images, labels)\n",
    "        \n",
    "\n",
    "        g_loss = generator_train_step(batch_size, discriminator, generator, g_optimizer, criterion)\n",
    "        \n",
    "        writer.add_scalars('scalars', {'g_loss': g_loss, 'd_loss': d_loss}, step)  \n",
    "        \n",
    "        if step % display_step == 0:\n",
    "            generator.eval()\n",
    "            z = Variable(torch.randn(9, 100)).cuda()\n",
    "            labels = Variable(torch.LongTensor(np.arange(9))).cuda()\n",
    "            sample_images = generator(z, labels).unsqueeze(1)\n",
    "            grid = make_grid(sample_images, nrow=3, normalize=True)\n",
    "            writer.add_image('sample_image', grid, step)\n",
    "    print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(generator.state_dict(), 'generator_state.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = Variable(torch.randn(100, 100)).cuda()\n",
    "labels = torch.LongTensor([i for i in range(10) for _ in range(10)]).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = generator(z, labels).unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = make_grid(images, nrow=10, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_digit(generator, digit):\n",
    "    z = Variable(torch.randn(1, 100)).cuda()\n",
    "    label = torch.LongTensor([digit]).cuda()\n",
    "    img = generator(z, label).data.cpu()\n",
    "    img = 0.5 * img + 0.5\n",
    "    return transforms.ToPILImage()(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABrElEQVR4nH2RsWsUURDGfzNvz8t55IxIPBKIqOQKMalEQULgBDGIYn9WqbRWOAS5v8JKSBFLO8UU2ihCBBHSCAaDxEYkd3IaL+Im4u2bWOxudpOo08yb97355vvmQRISp5MESVUCRQYCgO0YPE3EARDYStsYYHeUynEunoOy8J/4C6iCgo4MazJx9MxMd2suvD4xrs4BaNZ3NuytRBatPWw8ujvqplAMtgWgcnO+o4/fvZfqie7qbNdvooAeApBWa/nL7aX6WsTE0bo42jFtFaBpTxrT9drFyDamjo1fETTnzPvpYulNx8w+BKWCwvDBHfCa90McXjTzc1AQJwyC4ACk0Z+FQTO7kNgEIV40uNZx5LLZ8u59JJXeezHZbD8dyu7v5B59isK357M+vZRn+G7Wr2Wlq+TBr2bmr+7/AQA++h/e9+/vyAgKAs7H4MLz9Wdt6Y2FoJZqLYgAWlucV/lsvpquLedpLIxmkFs/Nx64THB6KH9brwSy+npzyeeFxHjxRrjS+f0r6pX3sgoiwalX5v3LZrCXE3ACuJEjAVD6h9n9IWg6IUAyC38A7amBtybg0EwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x1BAF3295DA0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_digit(generator, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
